{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use nearest neighbours for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***************## How to use nearest neighbours for Classification****************\n",
      "[3 6 2 9 0 3 2 3 8 7 7 3 3 1 4 2 9 3 4 1 9 5 0 2 6 5 1 0 3 9 4 8 2 6 5 9 5\n",
      " 5 6 9 5 8 3 8 5 8 0 8 9 2 2 1 1 3 5 9 7 7 7 5 6 5 8 5 7 9 8 0 7 0 9 6 2 3\n",
      " 9 4 4 0 8 8 2 1 5 7 0 7 4 5 8 2 0 9 7 2 6 5 9 1 1 8 1 9 3 4 7 2 6 5 2 2 7\n",
      " 2 3 9 3 5 4 7 5 1 0 9 0 0 5 5 9 9 1 3 5 4 8 6 3 3 7 3 6 7 6 7 3 7 0 7 2 0\n",
      " 1 9 5 8 1 4 3 9 7 8 5 2 9 2 6 6 9 2 4 9 2 0 6 1 7 9 4 4 8 2 2 8 1 1 1 0 6\n",
      " 1 1 6 0 5 3 6 9 6 8 0 0 6 4 8 6 3 4 8 0 3 0 6 2 8 8 3 8 5 3 3 4 0 7 8 4 9\n",
      " 9 9 4 3 9 4 6 8 4 3 7 6 1 3 3 1 5 6 8 2 5 5 2 4 3 0 6 8 4 4 0 6 2 6 7 7 8\n",
      " 5 9 2 6 5 0 8 5 9 3 2 1 1 6 3 6 4 7 5 3 8 0 8 6 5 5 6 2 9 5 0 4 5 1 9 4 2\n",
      " 1 9 3 8 8 6 0 0 7 7 8 1 9 9 3 6 7 3 1 2 0 3 9 0 2 4 1 0 3 0 0 2 5 6 0 0 0\n",
      " 7 4 8 6 8 1 8 9 8 6 4 1 5 0 6 3 8 7 0 5 7 3 1 1 4 2 3 7 2 2 3 5 4 6 6 4 0\n",
      " 2 2 8 5 5 0 4 1 9 6 5 9 2 1 5 9 4 1 2 4 1 1 9 0 0 2 9 7 6 8 7 1 2 4 8 0 5\n",
      " 4 7 8 2 7 3 6 0 2 5 3 5 4 1 9 0 8 3 2 2 3 6 2 5 0 2 6 1 6 3 2 4 0 7 3 9 6\n",
      " 6 5 9 2 3 9 8 2 0 7 2 6 6 7 8 1 1 7 0 1 3 0 3 7 9 3 6 4 4 0 7 8 9 9 5 1 7\n",
      " 0 1 6 1 3 8 9 9 8 0 9 8 6 2 2 8 0 8 9 8 6 2 4 5 2 7 4 3 2 4 7 9 8 4 5 3 0\n",
      " 8 8 7 6 6 5 2 5 2 7 5 2 8 9 3 6 7 4 8 0 8 0 9 1 5 1 8 1 6 9 5 9 8 2 0 2 6\n",
      " 3 7 4 1 0 3 4 5 4 7 5 8 8 3 4 0 0 5 3 0 1 3 0 1 7 8 3 7 6 4 7 7 1 0 1 5 5\n",
      " 0 2 4 4 5 8 5 0 4 7 7 2 7 2 5 0 4 0 8 0 7 4 0 0 5 3 1 5 3 4 3 6 5 3 9 7 0\n",
      " 3 7 8 8 4 7 8 4 4 4 0 8 6 5 7 6 5 6 3 1 5 0 8 4 7 9 2 3 3 1 8 9 6 9 8 3 7\n",
      " 2 3 8 7 8 9 1 8 9 4 4 5 1 9 6 2 1 3 1 6 8 7 3 3 6 2 1 9 5 9 2 6 5 8 5 0 6\n",
      " 1 2 0 2 5 4 7 5 2 0 5 5 8 5 3 0 7 4 6 2 7 0 9 4 9 0 6 2 7 1 7 0 0 1 1 8 9\n",
      " 5 6 5 6 4 7 9 7 2 0 0 9 3 4 6 4 4 4 7 9 1 3 7 2 1 4 3 4 0 1 3 9 3 2 8 6 3\n",
      " 5 2 9 0 5 4 0 8 1 2 3 9 6 7 6 1 7 7 1 2 7 4 2 1 8 4 9 5 0 9 9 8 8 4 9 0 1\n",
      " 1 5 8 4 7 3 8 2 1 1 3 1 2 4 9 3 1 5 2 5 9 9 5 2 9 9 7 6 6 6 2 9 6 8 7 8 8\n",
      " 4 1 9 8 7 4 1 6 4 2 3 8 8 1 8 4 9 1 0 1 8 7 6 7 3 7 3 5 9 5 6 2 2 1 8 4 7\n",
      " 5 6 7 9 3 7 2 4 3 7 9 7 9 1 9 6 7 3 7 6 6 4 5 0 2 5 1 8 5 9 3 4 8 0 4 5 2\n",
      " 4 3 1 2 6 3 5 9 0 8 1 6 1 2 2 3 9 0 6 1 4 8 6 4 5 0 7 1 4 0 2 3 4 4 7 7 2\n",
      " 9 7 2 0 3 4 2 1 4 1 5 6 4 3 9 8 6 5 1 7 0 1 6 7 1 6 6 7 9 2 9 3 7 4 9 1 5\n",
      " 4]\n",
      "Best Number Of Components: 18\n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
      "                     weights='uniform')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.33827893 0.24550898 0.31914894]\n",
      "\n",
      "0.3009789499856276\n",
      "\n",
      "0.03999314267040688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   19.5s finished\n"
     ]
    }
   ],
   "source": [
    "## How to use nearest neighbours for Classification\n",
    "def Snippet_155(): \n",
    "    print()\n",
    "    print(format('## How to use nearest neighbours for Classification','*^82'))  \n",
    "    \n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    # load libraries\n",
    "    from sklearn import decomposition, datasets\n",
    "    from sklearn import neighbors\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    # Load the iris flower data\n",
    "    dataset = datasets.make_classification(n_samples=1000, n_features=20, n_informative=5, \n",
    "                n_redundant=2, n_repeated=0, n_classes=10, n_clusters_per_class=2, \n",
    "                weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, \n",
    "                scale=1.0, shuffle=True, random_state=None)\n",
    "    X = dataset[0]\n",
    "    y = dataset[1]\n",
    "    \n",
    "#     print(y)\n",
    "    \n",
    "    # Create an scaler object\n",
    "    sc = StandardScaler()\n",
    "    # Create a pca object\n",
    "    pca = decomposition.PCA()\n",
    "    # Create a logistic regression object with an L2 penalty\n",
    "    KNN = neighbors.KNeighborsClassifier()\n",
    "    # Create a pipeline of three steps. First, standardize the data.\n",
    "    # Second, tranform the data with PCA.\n",
    "    # Third, train a Decision Tree Classifier on the data.\n",
    "    pipe = Pipeline(steps=[('sc', sc), \n",
    "                           ('pca', pca), \n",
    "                           ('KNN', KNN)])\n",
    "    \n",
    "    # Create Parameter Space\n",
    "    # Create a list of a sequence of integers from 1 to 30 (the number of features in X + 1)\n",
    "    n_components = list(range(1,X.shape[1]+1,1))\n",
    "    # Create lists of parameter for KNeighborsRegressor()\n",
    "    n_neighbors = [2, 3, 5, 10]\n",
    "    algorithm = ['auto',  'ball_tree', 'kd_tree', 'brute']\n",
    "    # Create a dictionary of all the parameter options \n",
    "    # Note has you can access the parameters of steps of a pipeline by using '__â€™\n",
    "    parameters = dict(pca__n_components=n_components,\n",
    "                      KNN__n_neighbors=n_neighbors,\n",
    "                      KNN__algorithm=algorithm)\n",
    "    \n",
    "    # Conduct Parameter Optmization With Pipeline\n",
    "    # Create a grid search object\n",
    "    clf = GridSearchCV(pipe, parameters)\n",
    "    # Fit the grid search\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    # View The Best Parameters\n",
    "    print('Best Number Of Components:', clf.best_estimator_.get_params()['pca__n_components'])\n",
    "    print(); print(clf.best_estimator_.get_params()['KNN'])\n",
    "    \n",
    "    # Use Cross Validation To Evaluate Model\n",
    "    CV_Result = cross_val_score(clf, X, y, cv=3, n_jobs=-1, scoring='accuracy', verbose=1)\n",
    "    print(); print(CV_Result)\n",
    "    print(); print(CV_Result.mean())\n",
    "    print(); print(CV_Result.std())    \n",
    "    \n",
    "Snippet_155()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
